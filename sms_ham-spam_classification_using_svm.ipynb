{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processed a dataset and learn SVM The dataset D2 is not preprocessed. It\n",
    "consists of label[ham or spam] and content of sms text. Your task in this part is to pre-process this data into\n",
    "a processable format. Using OneHotEnconding might not help, therefore you have to use other means of\n",
    "converting text data into features. You can look at scikit-learn text feature extraction utilities i.e. TFIDF or\n",
    "count. You might also want to get rid of the stop words i.e. This, the, is, a etc, which appear in almost all\n",
    "the documents. After preprocessing you have to use SVM implementation provided by scikit-learn. Here\n",
    "you will experiment with different hyperparameters and two kernels (linear and RBF). As usual you will\n",
    "perform 5-fold cross validation and present the score using plots and tables. You might also want to look\n",
    "at sklearn.pipeline.Pipeline utility to streamline your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikiran\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\saikiran\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:29: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores on rbf kernel are: [0.87623318385650228, 0.87174887892376685, 0.85906642728904847, 0.86445242369838415, 0.85816876122082586]\n",
      "scores on linear svm kernel are: [0.97040358744394617, 0.96771300448430497, 0.96678635547576297, 0.96588868940754036, 0.95960502692998206]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.86      1.00      0.92       956\n",
      "       spam       0.00      0.00      0.00       158\n",
      "\n",
      "avg / total       0.74      0.86      0.79      1114\n",
      "\n",
      "Mean Accuracy: of rbf kernel 0.858168761221\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.96      1.00      0.98       956\n",
      "       spam       1.00      0.72      0.83       158\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1114\n",
      "\n",
      "Mean Accuracy: of linear kernel 0.966079332748\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "data = {\"text\":[], \"class\":[]}\n",
    "\n",
    "f = open(\"C:\\Users\\saikiran\\Desktop\\SMSSpamCollection.txt\", \"r\")\n",
    "reader=csv.reader(f,delimiter='\\t')\n",
    "for target, value in reader:\n",
    "    tokens = []\n",
    "    token = tokenizer.tokenize(value)\n",
    "    for i in token:\n",
    "        if i not in stop:\n",
    "            tokens.append(i)\n",
    "\n",
    "    value = \" \".join(tokens).decode('utf-8', 'ignore')\n",
    "    data[\"text\"].append(value)\n",
    "    data[\"class\"].append(target)\n",
    "\n",
    "f.close()\n",
    "\n",
    "length = len(data[\"text\"])\n",
    "sample = random.sample(range(0, length), length)\n",
    "data[\"text\"] = [data[\"text\"][i] for i in sample]\n",
    "data[\"class\"] = [data[\"class\"][i] for i in sample]\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('vectorizer',  CountVectorizer(ngram_range=(1,20))),\n",
    "    ('classifier',  SVC(kernel='rbf')) ])\n",
    "pipeline2 = Pipeline([\n",
    "    ('vectorizer',  CountVectorizer(ngram_range=(1,20))),\n",
    "    ('classifier',  SVC(kernel='linear')) ])\n",
    "k_fold = KFold(n=len(data[\"text\"]), n_folds=5)\n",
    "new_data_text = np.asarray(data['text'])\n",
    "new_data_class = np.asarray(data['class'])\n",
    "scores_rbf = []\n",
    "scores_linear = []\n",
    "\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = new_data_text[train_indices]\n",
    "    train_y = new_data_class[train_indices]\n",
    "    \n",
    "    test_text = new_data_text[test_indices]\n",
    "    test_y = new_data_class[test_indices]\n",
    "    pipeline1.fit(train_text, train_y)\n",
    "    pipeline2.fit(train_text, train_y)\n",
    "    predicted_rbf = pipeline1.predict(test_text)\n",
    "    predicted_linear = pipeline2.predict(test_text)\n",
    "    score_rbf = pipeline1.score(test_text, test_y)\n",
    "    score_linear = pipeline2.score(test_text, test_y)\n",
    "    scores_rbf.append(score_rbf)\n",
    "    scores_linear.append(score_linear)\n",
    "print \"scores on rbf kernel are:\",scores_rbf\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print \"scores on linear svm kernel are:\",scores_linear\n",
    "print(metrics.classification_report(test_y, predicted_rbf, target_names=['ham', 'spam']))\n",
    "print \"Mean Accuracy: of rbf kernel \" + str(score_rbf)\n",
    "print(metrics.classification_report(test_y, predicted_linear, target_names=['ham', 'spam']))\n",
    "score_rbf = sum(scores_rbf) / len(scores_rbf)\n",
    "score_linear = sum(scores_linear) / len(scores_linear)\n",
    "print \"Mean Accuracy: of linear kernel \" + str(score_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Mean accuracy score using linear kernel is better to mean accuracy score of rbf kernel for this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
